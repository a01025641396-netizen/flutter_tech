캐시 메모리는 CPU(프로세서)와 메인 메모리(RAM) 사이의 속도 차이로 인한 병목 현상을 해결하기 위해 사용하는 고속 임시 저장소입니다.

1. 캐시 메모리를 사용하는 이유
CPU는 초당 수십억 번의 연산을 처리할 만큼 매우 빠르지만, 데이터를 가져오는 RAM은 상대적으로 훨씬 느립니다. CPU가 연산을 위해 RAM에서 데이터를 기다리는 시간이 길어지면 컴퓨터 전체의 성능이 저하됩니다.

이때, 자주 사용하는 데이터를 CPU 바로 옆의 아주 빠른 **캐시 메모리(SRAM)**에 미리 복사해 두면, CPU가 느린 RAM까지 가지 않고도 즉시 데이터를 처리할 수 있어 시스템의 전체적인 처리 속도가 비약적으로 향상됩니다.

2. 적중률(Hit Rate)을 높이는 원리: 지역성(Locality)
캐시는 공간이 매우 협소하기 때문에 '다음에 어떤 데이터가 사용될지' 정확히 예측하여 담아두는 것이 중요합니다. 이때 사용하는 핵심 원리가 바로 **참조 지역성의 원리(Principle of Locality)**입니다.

① 시간 지역성 (Temporal Locality)
개념: 한 번 참조된 데이터는 가까운 미래에 다시 참조될 가능성이 높다는 원리입니다.

예시: 루프(for, while) 문에서 사용하는 조건 변수나 반복적으로 호출되는 함수 코드 등.

캐시 전략: 최근에 사용한 데이터를 캐시에 우선적으로 보관합니다.

② 공간 지역성 (Spatial Locality)
개념: 특정 데이터가 참조되면, 그 인근에 있는 데이터가 곧 참조될 가능성이 높다는 원리입니다.

예시: 배열(Array) 데이터. a[0]을 읽었다면 곧 a[1], a[2]를 읽을 확률이 매우 높습니다.

캐시 전략: CPU가 데이터 하나를 요청해도 그 주변 데이터 블록 전체를 묶어서 캐시로 가져옵니다.

3. 캐시 적중(Hit)과 실패(Miss)
Cache Hit: CPU가 필요한 데이터가 캐시에 있는 상태. 즉시 데이터를 사용하여 속도가 매우 빠릅니다.

Cache Miss: 필요한 데이터가 캐시에 없어 RAM에서 가져와야 하는 상태. 속도가 급격히 느려집니다.

적중률(Hit Rate): 전체 참조 횟수 중 캐시 적중 횟수의 비율이며, 현대 컴퓨터는 보통 90% 이상의 적중률을 유지하도록 설계됩니다.
